---
title: "2020 US Ozone Nonattainment Analysis"
authors: "map579 & Microscone"
date: "7/29/2020"
output: html_document
---
## Purpose

This analysis is to estimate the current-to-date 4th max ozone values and 2018-2020 design values in the US.

Daily max 8-hour ozone data was retrieved from the EPA AQS API. 

```{r, include = FALSE}
library(httr)
library(jsonlite)
library(tidyverse)
library(lubridate)
library(gmodels)
library(knitr)
library(kableExtra)
library(leaflet)
library(data.table)
library(htmlwidgets)
library(htmltools)
library(readxl)
library(geojsonsf)
library(sp)
library(sf)
library(RCurl)
library(leafpop)
```


```{r, include = FALSE}
#Enter the year of data you want to analyze
Year_to_analyze <- "2020"

#converts the year to a date at the start of the ozone season
ozone_start_date <- as.Date(paste0(Year_to_analyze,"-05-01"))

#gets the date of "today", which is actually for "yesterday" to ensure that the analysis is current UP TO the current day.
Date_Today <- Sys.Date()-1

#converts the date of "today" to a character value without dashes
Today_characters <- paste0(substr(Date_Today,6,7),substr(Date_Today,9,10))

#creates a list of dates between the start of the ozone season and "today"
#removes the dashes from the dates and converts them all to characters
day_list <- str_remove_all(as.character(seq(ozone_start_date,Date_Today,1)),"-")

#main url for airnow daily files
airnowtech_files <- "https://s3-us-west-1.amazonaws.com//files.airnowtech.org/airnow/"

#name used for daily data files from airnow, which list the max concentrations for pollutants at each monitor each day
fileName <- "daily_data_v2.dat"

#creates a default folder on the computer
airnow_folder <- "c:/airnow/"

#creates a subfolder
ifelse(!dir.exists(file.path(airnow_folder,Year_to_analyze)), dir.create(file.path(airnow_folder,Year_to_analyze)), FALSE)

#creates a variable for the path of the subfolder
YOC_folder <- paste0(airnow_folder,Year_to_analyze,sep = "/")

#new subfolder name
dat_folder_name <- "Daily_Data_Files"

#creates another subfolder
ifelse(!dir.exists(file.path(YOC_folder,dat_folder_name)), dir.create(file.path(YOC_folder,dat_folder_name)), FALSE)

#another variable for the path of the final folder
dat_folder <- paste0(YOC_folder,dat_folder_name,sep = "/")

system.time(
#downloads the daily dat files for the selected year for the ozone season and places them in the download folder created.
for (i in day_list){
  destination_file <- paste0(dat_folder,i,fileName)
  #only downloads new files which have not already been downloaded
  if(!file.exists(destination_file)){
    temp_url <- paste0(airnowtech_files,Year_to_analyze,"/",i,"/",fileName)
    download.file(temp_url,destination_file)
  }
})

```


```{r, include = FALSE}

#list of dat files in folder
file_list <- list.files(dat_folder)

#empty data frame
dataset <- data.frame()

system.time(
#read and bind all dat files into the empty data frame
for (i in 1:length(file_list)){
  setwd(dat_folder)
  temp_data <- fread(file_list[i], sep = "|", header = F,  stringsAsFactors = F) 
  dataset <- rbindlist(list(dataset, temp_data), use.names = T) 
})

#----------
#ALTHOUGH NOT USED, THIS SECTION READS ALL DAT FILES DIRECTLY INTO A DATA FRAME, AS OPPOSED TO DOWNLOADING THEM 

# #empty data frame
# df_total = data.frame()
# 
# system.time(
# #loop to read the dat files for the selected days and copy into the empty data frame
# for (i in day_list){
#   temp_url <- paste0(airnowtech_files,Year_to_analyze,"/",i,"/",fileName)
#   data <- read.delim(temp_url, header = FALSE, sep="|", as.is=TRUE)
#   df_total <- rbind(df_total,data)
# })
 
#----------

#list of names for the header of the data frame
headers <- c("Date","Monitor_ID","SiteName","Param_Name","Units","Value","Averaging_Period","Data_Source",
            "AQI_Value","AQI_Category","Latitude","Longitude","AQSID")

#renaming header of data frame
colnames(dataset) <- headers

#copying data frame to a new working data frame
AQ2020 <- dataset

# #converting Date field from a character to a date.
# AQ2020$POSIX.Date <- as.POSIXct(paste0(AQ2020$Date,"20"), format = '%m/%d/%Y')

AQ2020$CountryCode <- substring(AQ2020$AQSID,1,3)

countryCodeList <- unique(AQ2020$CountryCode)

US_Country_Codes <- c('840','021','001','093','113')

#selecting only the records for monitors in the Philly NAA for 8hr ozone average max values
US_daily_max <- AQ2020 %>% 
  filter(CountryCode %in% US_Country_Codes) %>%
  filter(Param_Name == "OZONE-8HR") %>%
  rename("Avg_8hr" = Value)

num_exceedences <- US_daily_max %>% 
    filter(Avg_8hr > 70)

#calculates how many values are included for each monitor in the US_4thMax df
exceedences_by_mon <- plyr::ddply(US_daily_max,~Monitor_ID,summarise,'days_>70ppb'=sum(Avg_8hr > 70))

US_mon_coords <- US_daily_max %>%
  select(Monitor_ID,SiteName,Longitude,Latitude) %>%
  group_by(Monitor_ID) %>% 
  slice(1) %>% 
  left_join(.,exceedences_by_mon, by = "Monitor_ID", keep = F)


#selecting the 4 highest 8hr ozone max values for each monitor in the Philly NAA
US_4_Highest <- AQ2020 %>% 
  filter(CountryCode %in% US_Country_Codes) %>%
  filter(Param_Name == "OZONE-8HR") %>%
  rename("Avg_8hr_4thMax" = Value) %>%
  group_by(Monitor_ID) %>% 
  arrange(desc(AQI_Value)) %>% 
  slice(1:4)

#calculates how many values are included for each monitor in the US_4thMax df
num_monitors <- plyr::ddply(US_4_Highest,~Monitor_ID,summarise,num_days=length(unique(Date)))

#empty vector
num_vec <- c()

#loop to create a list of values (1 through 4) to represent the n-highest values by monitor
#the values create this list based upon the monitors and numbers in num_monitors
for (i in 1:nrow(num_monitors)){
  z <- seq(1,num_monitors[i,2],1)
  end <- length(num_vec)+1
  num_vec <- append(num_vec,z,end)
}

#the num_vec of values representing the n-highest values are added to the df
US_4_Highest$n_highest <- num_vec

#a "wide" pivot table is created which includes columsn for the 4 highest ozone values
US_Pivot <- US_4_Highest %>%
  select(Monitor_ID,SiteName,Avg_8hr_4thMax,n_highest) %>%
  pivot_wider(names_from = n_highest,values_from = Avg_8hr_4thMax)

#renaming columns of pivot table
colnames(US_Pivot) <- c("Monitor_ID","SiteName","2020_Max","2020_2nd_High","2020_3rd_High","2020_4th_High")

#alternate df of US_Pivot to include coordinates
US_Pivot_Coords <- US_Pivot %>%
  left_join(.,US_mon_coords, by = c("Monitor_ID","SiteName"), keep = F)

```



```{r, include = FALSE}

#url of official ozone design values for 2019
ozoneDV2019_file <- "https://www.epa.gov/sites/production/files/2020-05/o3_designvalues_2017_2019_final_05_26_20.xlsx"

#temporary location for downloading file
temp_excel <- tempfile(fileext = ".xlsx")

#downloads the excel file to the temporary location
download.file(ozoneDV2019_file,destfile = temp_excel, mode = 'wb')

#reads the temporary excel file into a data frame
ozoneDV2019 <- read_excel(temp_excel, "Table5. Site Status", skip = 3, col_names = T)

#shortened list of header names
headersDVfile <- c("State","County","CBSA","CSA","NAA_Name","EPA_Region","Monitor_ID","SiteName","SiteAddress",
                   "Latitude","Longitude","Valid_17_19_DV","Invalid_17_19_DV","Avg_17_19_Completeness","Completeness_2017",
                   "Completeness_2018","Completeness_2019","2017_4thMax","2018_4thMax","2019_4thMax","2017_Exceedance_Days",
                   "2018_Exceedance_Days","2019_Exceedance_Days")

#applying header names to data frame
colnames(ozoneDV2019) <- headersDVfile

#duplicates data frame from the original
ozondDV2019df <- ozoneDV2019

#converts the ppm values to ppb values
ozondDV2019df$`2018_4thMax` <- ozondDV2019df$`2018_4thMax`*1000
ozondDV2019df$`2019_4thMax` <- ozondDV2019df$`2019_4thMax`*1000

#removes the comma and state abbreviations in the NAA names in order to match those in the NAA polygon file, below.
ozondDV2019df$NAA_Name <- substr(ozondDV2019df$NAA_Name,1,regexpr(",",ozondDV2019df$NAA_Name)-1)

#the names of these two NAAs are adjusted to match the names in the NAA polygon file, below.
ozondDV2019df[ozondDV2019df == 'Dona Ana County (Sunland Park)'] <- 'Dona Ana County (Sunland Park Area)'
ozondDV2019df[ozondDV2019df == 'Pechanga Band of Luiseno Mission Indians'] <- 'Pechanga Band of Luiseno Mission Indians of the Pechanga Reservation'

#filters the 2019 DV data for the Philly monitors, joins the 2020 4th Max value to the table
US_2020DV <- ozondDV2019df %>%
  select(State,County,Monitor_ID,NAA_Name,Latitude,Longitude,`2018_4thMax`,`2019_4thMax`) %>%
  left_join(.,US_Pivot, by = "Monitor_ID", keep = F) 
  
#calculates the draft 2018-2020 design value for ozone for the monitors in the Philly NAA
US_2020DV$Draft_DV_18_20 <- apply(US_2020DV[,c(7,8,13)], 1, function(x) trunc(mean(x)))

#removes records with no draft DV for 2020
US_2020DV <- US_2020DV %>%
 filter(!is.na(Draft_DV_18_20))
  

```



```{r, echo=FALSE}

#bins the draft design value data, above and below the 0.070ppm ozone NAAQS
US_Pivot_Coords$O3_2020_4thMax <- cut(US_Pivot_Coords$`2020_4th_High`,c(0,60,65,70,75,80,150), include.lowest = T,labels = c('< 61','61-65','66-70','71-75','76-80','>80'))

#bins the draft design value data, above and below the 0.070ppm ozone NAAQS
US_2020DV$O3_NAAQS_Attainment <- cut(US_2020DV$Draft_DV_18_20,c(0,60,65,70,75,80,150), include.lowest = T,labels = c('< 61','61-65','66-70','71-75','76-80','>80'))

#color pallette is set
monitorCol <- colorFactor(c('blue','purple','green','yellow','orange','red'), 
                          domain = c('< 61','61-65','66-70','71-75','76-80','>80'))

#alters the leaflet html options for styling the title of the map
tag.map.title <- tags$style(HTML("
  .leaflet-control.map-title { 
    transform: translate(-50%,20%);
    position: fixed !important;
    left: 50%;
    text-align: center;
    padding-left: 8px; 
    padding-right: 8px; 
    background: rgba(192,192,192,1);
    font-weight: bold;
    font-size: 18px;
  }
"))

#specifies value of title
title <- tags$div(
  tag.map.title, HTML(paste0("AirNow Data From ",ozone_start_date," Through ",Date_Today))
)  

# # reading GeoJSON file for NAA boundaries
# US_2015_O3_NAA <- geojson_sf("US_2015_ozone_NAA_4326.geojson")
# 
# #unique list of NAAs and the design value site for each, based upon highes draft 2020 DV
# NAA_DV_Site <- US_2020DV %>%
#   select(Monitor_ID,SiteName,NAA_Name,Draft_DV_18_20) %>%
#   filter(!is.na(NAA_Name)) %>%
#   group_by(NAA_Name) %>% 
#   arrange(desc(Draft_DV_18_20)) %>% 
#   slice(1)
# 
# #design value data of NAA_DV_Site is merged with the spatial data of the NAA polygons, to create a new layer
# new_NAA_Polygons <- merge(US_2015_O3_NAA,NAA_DV_Site,by.x='area_name',by.y='NAA_Name')

# # reading GeoJSON file for state
# US_states <- geojson_sf("US_States_4326.geojson")

# #creates a orange color palette for the various NAA classifications
# naa_pal <- colorFactor(
#   palette = "Oranges",
#   domain = US_2015_O3_NAA$classification)

# The Leaflet map widget is set to a variable "map".
# Layers are defined for use with an interactive layer display.
map_combined <- leaflet() %>% 
  
  # the zoom and center is set
  setView(-77, 39, zoom = 5) %>%
  
  #a basemap is added
  addProviderTiles(providers$CartoDB.Positron) %>%
  
  # # a polygon layer is added for the US NAA object and its outline color and opacity are set
  # addPolygons(data=new_NAA_Polygons,
  #             stroke = TRUE,
  #             weight = 2,
  #             color = "black",
  #             smoothFactor = 0.2,
  #             fillOpacity = .8,
  #             fillColor = ~naa_pal(classification),
  #             popup = as.character(paste0(new_NAA_Polygons$area_name," NAA","<br>",
  #                                         "Classification: ",new_NAA_Polygons$classification,"<br>",
  #                                         "Design Value Site Name: ",new_NAA_Polygons$SiteName,"<br>",
  #                                         "Design Value Site ID: ",new_NAA_Polygons$Monitor_ID,"<br>",
  #                                         "Design Value Site 2020 DV: ",new_NAA_Polygons$Draft_DV_18_20))) %>%
  
  # # a polygon layer is added for the US states object and its outline color and opacity are set
  # addPolygons(data=US_states,
  #             stroke = TRUE,
  #             smoothFactor = 0.2,
  #             weight = 2,
  #             opacity = 1.0,
  #             color = "black",
  #             fillColor = "transparent") %>%
  
  # # add circle markers for the monitors
  # addCircleMarkers(data = US_Pivot_Coords,
  #                  ~Longitude,
  #                  ~Latitude,
  #                  popup = as.character(paste0("Site Name: ",US_Pivot_Coords$SiteName,"<br>",
  #                                              "AQS ID: ",US_Pivot_Coords$Monitor_ID,"<br>",
  #                                              "2020 4th Max: ",US_Pivot_Coords$`2020_4th_High`," ppb","<br>",
  #                                              "# Days >70ppb: ",US_Pivot_Coords$`days_>70ppb`)),
  #                  label = as.character(US_Pivot_Coords$SiteName),
  #                  labelOptions = labelOptions(textsize = "15px"),
  #                  color = ~monitorCol(O3_2020_4thMax),
  #                  radius = 4,
  #                  stroke = F, fillOpacity = 1,
  #                  group = "2020 4th Max") %>%
  # 
  # # add circle markers for the monitors
  # addCircleMarkers(data = US_2020DV,
  #                  ~Longitude,
  #                  ~Latitude,
  #                  popup = as.character(paste0("Site Name: ",US_2020DV$SiteName,"<br>",
  #                                              "AQS ID: ",US_2020DV$Monitor_ID,"<br>",
  #                                              "2020 Draft DV: ",US_2020DV$Draft_DV_18_20," ppb")),
  #                  label = as.character(US_2020DV$SiteName),
  #                  labelOptions = labelOptions(textsize = "15px"),
  #                  color = ~monitorCol(O3_NAAQS_Attainment),
  #                  radius = 4,
  #                  stroke = F, fillOpacity = 1,
  #                  group = "2020 DV") %>%

  # add circle markers for the monitors
  addCircleMarkers(data = US_Pivot_Coords,
                   ~Longitude,
                   ~Latitude,
                   popup = popupTable(US_Pivot_Coords),
                   label = as.character(US_Pivot_Coords$SiteName),
                   labelOptions = labelOptions(textsize = "15px"),
                   color = ~monitorCol(O3_2020_4thMax),
                   radius = 4,
                   stroke = F, fillOpacity = 1,
                   group = "2020 4th Max") %>%

  # add circle markers for the monitors
  addCircleMarkers(data = US_2020DV,
                   ~Longitude,
                   ~Latitude,
                   popup = popupTable(US_2020DV),
                   label = as.character(US_2020DV$SiteName),
                   labelOptions = labelOptions(textsize = "15px"),
                   color = ~monitorCol(O3_NAAQS_Attainment),
                   radius = 4,
                   stroke = F, fillOpacity = 1,
                   group = "2020 DV") %>%
  
  # add legend for the ozone values
  addLegend('bottomleft', pal = monitorCol, values = US_Pivot_Coords$O3_2020_4thMax,
            title = '2020 Preliminary Ozone Values',opacity = 1) %>%
  
  # adds radio buttons for switching layers between 4th max and DV values
  addLayersControl(baseGroups = c("2020 4th Max", "2020 DV"),options = layersControlOptions(collapsed = FALSE)) %>%
  
  # # add legend for the NAA classifications
  # addLegend('bottomright', pal = naa_pal, values = US_2015_O3_NAA$classification,
  #           title = '2015 Ozone NAA Classifications',opacity = 1) %>%
  
  # adds a title in the top of the map
  addControl(title, position = "topright", className="map-title")


#the map object is called, to create the leaflet map.
map_combined

#creates a filename
htmlFileName <- paste0(YOC_folder,"2020_Draft_Ozone_Values",".html")

# exporting the map widget to a single html file
saveWidget(map_combined, htmlFileName, selfcontained = TRUE)


```


```{r, echo=FALSE}

#uploads html file to SCMP website via FTP
login <- "epiz_26445108"
secret <- "d5mTGZejwP4jfn6"
uploadSite1 <- "ftp://185.27.134.11//htdocs/ozone/"
uploadFileName <- "2020_Draft_Ozone_Values"

ftpUpload(htmlFileName,
          paste0(uploadSite,uploadFileName,".html"),
          verbose = TRUE,
          userpwd = paste0(login,":",secret))



         





